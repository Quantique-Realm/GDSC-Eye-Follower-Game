{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the two main classes FaceAnalyzer and Face\n",
    "from FaceAnalyzer import FaceAnalyzer, Face\n",
    "import cv2 as cv\n",
    "\n",
    "fa = FaceAnalyzer()\n",
    "# ... Recover an image in RGB format as numpy array (you can use pillow opencv but if you use opencv make sure you change the color space from BGR to RGB)\n",
    "# Now process the image\n",
    "image  = cv.imread(f'face.jpg')\n",
    "fa.process(image)\n",
    "\n",
    "# Now you can find faces in fa.faces which is a list of instances of object Face\n",
    "if fa.nb_faces>0:\n",
    "    print(f\"{fa.nb_faces} Faces found\")\n",
    "    # We can get the landmarks in numpy format NX3 where N is the number of the landmarks and 3 is x,y,z coordinates\n",
    "    print(fa.faces[0].npLandmarks)\n",
    "    # We can draw all landmarks\n",
    "    # Get head position and orientation compared to the reference pose (here the first frame will define the orientation 0,0,0)\n",
    "    pos, ori = fa.faces[0].get_head_posture()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.55257914],\n",
       "       [ -3.49291148],\n",
       "       [403.49760596]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09421726],\n",
       "       [ 0.06091542],\n",
       "       [-0.01784859]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\FaceAnalyzer\\Face.py:1716: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(region)>=3,\"Region should contain at least 3 points\")\n",
      "c:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\FaceAnalyzer\\Face.py:1716: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(region)>=3,\"Region should contain at least 3 points\")\n",
      "c:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\FaceAnalyzer\\Face.py:1716: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(region)>=3,\"Region should contain at least 3 points\")\n",
      "c:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\FaceAnalyzer\\Face.py:1716: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(region)>=3,\"Region should contain at least 3 points\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FaceAnalyzer' object has no attribute 'ready'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Face\u001b[38;5;241m.\u001b[39mget_landmark_pos(fa, index\u001b[38;5;241m=\u001b[39mfa\u001b[38;5;241m.\u001b[39mfaces[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnpLandmarks)\n",
      "File \u001b[1;32mc:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\FaceAnalyzer\\Face.py:547\u001b[0m, in \u001b[0;36mFace.get_landmark_pos\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Recovers the position of a landmark from a results array\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    Tuple: Landmark 3D position in image space\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# Assertion to verify that the face object is ready\u001b[39;00m\n\u001b[1;32m--> 547\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFace object is not ready. There are no landmarks extracted.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m lm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpLandmarks[index, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([lm[\u001b[38;5;241m0\u001b[39m], lm[\u001b[38;5;241m1\u001b[39m], lm[\u001b[38;5;241m2\u001b[39m]])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FaceAnalyzer' object has no attribute 'ready'"
     ]
    }
   ],
   "source": [
    "Face.get_landmark_pos(fa, index=fa.faces[0].npLandmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n",
      "BLINK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWin\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m     45\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     48\u001b[0m     exit()\n\u001b[0;32m     50\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "# import mediapipe as mp\n",
    "from FaceAnalyzer import FaceAnalyzer, Face\n",
    "# import pyautogui as pyg\n",
    "# from time import sleep\n",
    "\n",
    "fa = FaceAnalyzer(1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "threshold = 0.4\n",
    "avgh = 0\n",
    "avgNum = 3\n",
    "lastVals = [0 for x in range(avgNum)]\n",
    "counter = 0\n",
    "\n",
    "scrollSens = 200\n",
    "\n",
    "while True:\n",
    "    success, image = cap.read()\n",
    "    RGB_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fa.process(RGB_image)\n",
    "\n",
    "    if(fa.found_faces):\n",
    "        if(counter >= avgNum):\n",
    "            counter = 0\n",
    "\n",
    "        Face.draw_eyes_landmarks(fa.faces[0], image)\n",
    "\n",
    "        h = Face.get_right_eye_height(fa.faces[0])\n",
    "\n",
    "        lastVals[counter] = h\n",
    "        avgh = 0\n",
    "        for x in lastVals:\n",
    "            avgh += x\n",
    "        avgh /= avgNum\n",
    "\n",
    "        #print([avgh, h, avgh-h])\n",
    "\n",
    "        if(avgh - h > threshold):\n",
    "            # pyg.scroll(-scrollSens)\n",
    "            # print (counter)\n",
    "            print(\"BLINK\")\n",
    "\n",
    "    cv2.imshow(\"Win\", image)\n",
    "    # cv2.waitKey(1)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        exit()\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python.exe -m pip install --upgrade pip\n",
    "# !pip uninstall mediapipe -y\n",
    "# !pip install mediapipe\n",
    "!pip install --upgrade mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Varad\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "center\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "right\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "center\n",
      "left\n",
      "center\n",
      "left\n",
      "right\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "center\n",
      "center\n",
      "blink\n",
      "center\n",
      "center\n",
      "center\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "right\n",
      "right\n",
      "center\n",
      "blink\n",
      "left\n",
      "center\n",
      "center\n",
      "left\n",
      "center\n",
      "left\n",
      "left\n",
      "left\n",
      "center\n",
      "blink\n",
      "center\n",
      "center\n",
      "center\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "center\n",
      "center\n",
      "center\n",
      "left\n",
      "right\n",
      "right\n",
      "center\n",
      "center\n",
      "center\n",
      "center\n",
      "left\n",
      "center\n",
      "left\n",
      "right\n",
      "right\n",
      "center\n",
      "center\n",
      "center\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n",
      "left\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from FaceAnalyzer import FaceAnalyzer, Face\n",
    "import pyautogui as pyg\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "fa = FaceAnalyzer(1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "threshold = 0.8\n",
    "avgh = 0\n",
    "avgNum = 3\n",
    "lastVals = [0 for x in range(avgNum)]\n",
    "\n",
    "avgh_l = 0\n",
    "avgNum_l = 3\n",
    "lastVals_l = [0 for x in range(avgNum_l)]\n",
    "counter = 0\n",
    "\n",
    "scrollSens = 200\n",
    "y_pred = []\n",
    "while True:\n",
    "    success, image = cap.read()\n",
    "    image = cv2.flip(image,1)\n",
    "    RGB_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fa.process(RGB_image)\n",
    "\n",
    "    if(fa.found_faces):\n",
    "        Face.draw_eyes_landmarks(fa.faces[0], image)\n",
    "        # print(fa.faces[0].landmarks)\n",
    "        # print(Face.get_3d_realigned_landmarks_pos(fa.faces[0], [473]))\n",
    "        # Face.reset_face_3d_reference_positions(fa.faces[0])\n",
    "        # Face.draw_landmark_by_index(fa.faces[0], image, 473, thickness=1)\n",
    "        # position = Face.get_eyes_position(fa.faces[0])\n",
    "        # print(position)\n",
    "\n",
    "        real = Face.get_realigned_landmarks_pos(fa.faces[0], [473, 362, 263])\n",
    "        Face.draw_landmark_by_index(fa.faces[0], image, 473, color=(0,0,255), thickness=2)\n",
    "\n",
    "        if(counter >= avgNum):\n",
    "            counter = 0\n",
    "\n",
    "        # Face.draw_eyes_landmarks(fa.faces[0], image)\n",
    "\n",
    "        h = Face.get_right_eye_height(fa.faces[0])\n",
    "        hl = Face.get_left_eye_height(fa.faces[0])\n",
    "\n",
    "        lastVals[counter] = h\n",
    "        avgh = 0\n",
    "        for x in lastVals:\n",
    "            avgh += x\n",
    "        avgh /= avgNum\n",
    "        h = 1 if avgh - h > threshold else 0\n",
    "\n",
    "        lastVals_l[counter] = hl\n",
    "        avgh_l = 0\n",
    "\n",
    "        for x in lastVals:\n",
    "            avgh_l += x\n",
    "        avgh_l /= avgNum_l\n",
    "        hl = 1 if avgh_l - hl > threshold else 0\n",
    "        #print([avgh, h, avgh-h])\n",
    "        \n",
    "\n",
    "        # print(real)\n",
    "\n",
    "        # h = Face.get_right_eye_height(fa.faces[0])\n",
    "        # lastVals[counter] = h\n",
    "        # avgh = 0\n",
    "        # for x in lastVals:\n",
    "        #     avgh += x\n",
    "        # avgh /= avgNum\n",
    "\n",
    "        landmarks_pos = Face.get_landmarks_pos(fa.faces[0], [473, 362, 263, 475]) #3d array\n",
    "        # print(landmarks_pos)\n",
    "        \n",
    "        '''distn for left (473, 362) || distn for right (473, 263)'''\n",
    "        pupil = landmarks_pos[0]\n",
    "        left = landmarks_pos[1]\n",
    "        right = landmarks_pos[2]\n",
    "\n",
    "        l_dist = sqrt(((pupil[0]-left[0])**2)+((pupil[1]-left[1])**2)+((pupil[2]-left[2])**2))\n",
    "        r_dist = sqrt(((pupil[0]-right[0])**2)+((pupil[1]-right[1])**2)+((pupil[2]-right[2])**2))\n",
    "\n",
    "        # print(l_dist, r_dist, l_dist+r_dist)\n",
    "\n",
    "        # if(l_dist>22 and r_dist>22): print('center')\n",
    "\n",
    "        # lastVals[counter] = h\n",
    "        # avgh = 0\n",
    "        # for x in lastVals:\n",
    "        #     avgh += x\n",
    "        # avgh /= avgNum\n",
    "        # if(avgh - h > threshold):\n",
    "        #     print(\"BLINK\")\n",
    "    counter += 1\n",
    "    cv2.imshow(\"Win\", image)\n",
    "\n",
    "    if len(y_pred)==20:\n",
    "        import statistics\n",
    "        prediction = statistics.mode(y_pred)\n",
    "        print(prediction)\n",
    "        y_pred.clear()\n",
    "\n",
    "    if(l_dist<24): \n",
    "        y_pred.append('left')\n",
    "        continue\n",
    "    elif(r_dist<20): \n",
    "        y_pred.append('right')\n",
    "        continue\n",
    "    else: \n",
    "        y_pred.append('center')\n",
    "    if(h and hl): \n",
    "        print('blink')\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 473, 362, 263\n",
    "left_eye_contour_indices = [\n",
    "                                    476, # Right\n",
    "                                    477, # Bottom\n",
    "                                    474, # Left\n",
    "                                    475  # Top\n",
    "                                ]\n",
    "left_eye_left_right_indices = [\n",
    "                                    362, # Right\n",
    "                                    263, # Left\n",
    "                                ]                                \n",
    "left_eye_center_index = 473\n",
    "#################################################################\n",
    "right_eye_contour_indices = [\n",
    "                                    471, # right\n",
    "                                    472, # bottom\n",
    "                                    469, # left\n",
    "                                    470  # top\n",
    "                                ]\n",
    "right_eye_left_right_indices = [\n",
    "                                    130, # Right\n",
    "                                    133, # Left\n",
    "                                ]                                   \n",
    "right_eye_center_index = 468    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faceAna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
